model_category,dataset_num,name,title,description,id_name,id_description,target_name,target_description,use_dataset,is_smoke_test,encoding
text_classification_base,1,clickbait,Clickbait,"This dataset contains a collection of two types of headlines - clickbait and non-clickbait. The clickbait article headlines are collected from �BuzzFeed�, �Upworthy�, �ViralNova�, �Thatscoop�, �Scoopwhoop� and �ViralStories�. The non-clickbait article headlines are collected from �WikiNews�, �New York Times�, �The Guardian�, and �The Hindu�. The task is to accurately classify a headline into the clickbait or non-clickbait class.",id,Unique identifier for each sample in the dataset.,class,..,1,0,utf-8
text_classification_base,2,drug_reviews,Drug Reviews,"The dataset provides patient reviews on specific drugs along with related conditions. Furthermore, reviews are grouped into reports on the three aspects benefits, side effects and overall comment. Additionally, ratings are available concerning overall satisfaction as well as a 5 step side effect rating and a 5 step effectiveness rating. The data was obtained by crawling online pharmaceutical review sites.",id,Unique identifier for each sample in the dataset.,effectiveness,..,1,0,utf-8
text_classification_base,3,ecommerce_categories,Ecommerce Categories,"This is the classification based E-commerce text dataset. There are 4 categories of products - ""Electronics"", ""Household"", ""Books"" and ""Clothing & Accessories"", which are the most common products sold on most ecommerce websites. The task is to predict the category of the product given its description.",id,Unique identifier for each sample in the dataset.,category,..,1,0,utf-8
text_classification_base,4,fake_job_postings,Fake Job Postings,This dataset contains ~18K job descriptions out of which about 800 are fake. The data consists of both textual information and meta-information about the jobs. The dataset can be used to create classification models which can learn the job descriptions which are fraudulent.,job_id,Unique identifier for each sample in the dataset.,fraudulent,..,1,0,utf-8
text_classification_base,5,hate_speech,Hate Speech,"This dataset contains 24783 tweets which have been categorized into three classes: offensive language, hate speech, and neither. The task is to accurate categorize each tweet into the correct class. Caution: The data contains content that is racist, sexist, homophobic, and offensive in many ways.",id,Unique identifier for each sample in the dataset.,class,..,1,0,utf-8
text_classification_base,6,movie_reviews,Movie Reviews,"This dataset contains 2,000 movie review documents labeled with respect to their overall sentiment polarity (positive or negative). The task is to predict the sentiment polarity using the review text.",id,Unique identifier for each sample in the dataset.,class,..,1,0,utf-8
text_classification_base,7,newsgroups,Newsgroups,"The newsgroups dataset comprises around ~18,000 newsgroups posts that are organized into 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g. comp.sys.ibm.pc.hardware / comp.sys.mac.hardware), while others are highly unrelated (e.g misc.forsale / soc.religion.christian).",id,Unique identifier for each sample in the dataset.,newsgroup,..,1,0,utf-8
text_classification_base,8,spam_text,Spam Text,The SMS Spam Collection is a public set of SMS labeled messages that have been collected for mobile phone spam research. The task involves classifying the messages into spam or ham (i.e. not-spam).,Id,Unique identifier for each sample in the dataset.,Category,..,1,0,utf-8
text_classification_base,9,tweet_emotions,Tweet Emotions,The data is a collection of tweets annotated with the emotions behind them.,tweet_id,Unique identifier for each sample in the dataset.,sentiment,..,1,0,utf-8
text_classification_base,10,imdb,IMDB,"This is a dataset for binary sentiment classification. It contains a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. For more information, refer to: https://ai.stanford.edu/~amaas/data/sentiment/",id,Unique identifier for each sample in the dataset.,class,The sentiment of the review (pos or neg),1,0,utf-8
text_classification_base,11,cola,CoLA,"The Corpus of Linguistic Acceptability (CoLA) in its full form consists of 10657 sentences from 23 linguistics publications, expertly annotated for acceptability (grammaticality) by their original authors. The public version provided here contains 9594 sentences belonging to training and development sets, and excludes 1063 sentences belonging to a held out test set.",id,Unique identifier for each sample in the dataset.,acceptability,"the acceptability judgment label (0=unacceptable, 1=acceptable).",1,0,utf-8